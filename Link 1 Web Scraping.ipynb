{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25be54c8",
   "metadata": {},
   "source": [
    "Done By Nahian Tahmin\n",
    "\n",
    "25th Janury 2022 \n",
    "\n",
    "iTQAN Intern Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea2d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e622856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "def get_my_soup(link):\n",
    "    #this function gets the link's content and returns it in the form of bs4 soup\n",
    "    \n",
    "    driver.get(link)\n",
    "    content = driver.page_source\n",
    "    my_soup = BeautifulSoup(content)\n",
    "    \n",
    "    return my_soup\n",
    "    \n",
    "def find_all_class(my_soup, tag_type, tag_name):\n",
    "    #this function is a wrapper for findAll function of beautifulsoup\n",
    "    \n",
    "    return my_soup.findAll(tag_type, attrs={'class': tag_name})\n",
    "\n",
    "def find_first(my_soup, tag_type, tag_name):\n",
    "    #this function is a wrapper for find function of beautifulsoup\n",
    "    \n",
    "    return my_soup.find(tag_type, attrs={'class': tag_name})\n",
    "\n",
    "def content_iterator(tag_list):\n",
    "    #this function iterates on tags like <li>, <span>, etc to get their contents in a list form\n",
    "    \n",
    "    my_list = []\n",
    "    \n",
    "    for data in tag_list:\n",
    "        if data.text !='\\n' and data.text != ' ' and data.text != '':\n",
    "            my_list.append(data.text.strip())\n",
    "            \n",
    "    return my_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f58235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_10376/1442039350.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"chromedriver_win32/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "phones = []\n",
    "addresses = []\n",
    "insurance = []\n",
    "additional_add = []\n",
    "page_hrefs = []\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver_win32/chromedriver\")\n",
    "main_link = \"https://www.psychologytoday.com/us/therapists/10956?zipdist=2&fbclid=IwAR2qm-vECbZmDa7SwHG2PyKX2C716zdvkN_hKDN1xAWLL0JmiJYYDM8FDT0\"\n",
    "soup = get_my_soup(main_link)\n",
    "\n",
    "#getting the links to all the pages\n",
    "for a in find_all_class(soup, 'a', 'pager-page'):\n",
    "    page_hrefs.append(a['href'])\n",
    "\n",
    "#going forward with only three links\n",
    "page_hrefs = page_hrefs[:3]\n",
    "\n",
    "#looping through the first three pages\n",
    "for link in page_hrefs:\n",
    "\n",
    "    soup = get_my_soup(link)\n",
    "\n",
    "    #looping to get all the details from each page\n",
    "    for a in find_all_class(soup, 'div', 'result-row normal-result row'):\n",
    "\n",
    "        name = find_first(a, 'a', 'result-name')\n",
    "        phone = find_first(a, 'div', 'result-phone')\n",
    "        address = find_first(a,'div', 'result-address')\n",
    "\n",
    "        #getting the on-click detailed description page contents\n",
    "        soup2 = get_my_soup(name['href'])\n",
    "\n",
    "        ins = find_first(soup2, 'ul', 'attribute-list')\n",
    "        ins_list = content_iterator(ins)\n",
    "\n",
    "        #print(ins_list)\n",
    "\n",
    "        additional = find_first(soup2, 'div', 'address-data')\n",
    "        additional_list = content_iterator(additional)\n",
    "\n",
    "        #print(additional_list)\n",
    "\n",
    "        #storing the desired details in the appropriate lists\n",
    "        names.append(re.sub('\\n+',' ',name.text).strip())\n",
    "        phones.append(phone.text.strip('\\n').strip())\n",
    "        addresses.append(address.text.strip('\\n'))\n",
    "        insurance.append(ins_list)\n",
    "        additional_add.append(additional_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df3e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset with the extracted data\n",
    "df = pd.DataFrame({'Name': names, 'Address': addresses,'Phone Number': phones, 'Accepted Insurance': insurance, 'Additional Address': additional_add}) \n",
    "df.to_csv('dataset1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c09685",
   "metadata": {},
   "source": [
    "End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
