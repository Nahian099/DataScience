{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca021c37",
   "metadata": {},
   "source": [
    "Done By Nahian Tahmin\n",
    "\n",
    "26th Janury 2022\n",
    "\n",
    "iTQAN Intern Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23befd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c4174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "def get_my_soup(link):\n",
    "    #this function gets the link's content and returns it in the form of bs4 soup\n",
    "    \n",
    "    driver.get(link)\n",
    "    content = driver.page_source\n",
    "    my_soup = BeautifulSoup(content)\n",
    "    \n",
    "    return my_soup\n",
    "    \n",
    "def find_all_class(my_soup, tag_type, tag_name):\n",
    "    #this function is a wrapper for findAll function of beautifulsoup\n",
    "    \n",
    "    return my_soup.findAll(tag_type, attrs={'class': tag_name})\n",
    "\n",
    "def find_first(my_soup, tag_type, tag_name):\n",
    "    #this function is a wrapper for find function of beautifulsoup\n",
    "    \n",
    "    return my_soup.find(tag_type, attrs={'class': tag_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7c5bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_8152/2107236484.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"chromedriver_win32/chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "team_names = []\n",
    "year = []\n",
    "wins = []\n",
    "losses = []\n",
    "OT_losses = []\n",
    "win_percent = []\n",
    "gf = []\n",
    "ga = []\n",
    "differences = []\n",
    "page_hrefs = []\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver_win32/chromedriver\")\n",
    "main_link = \"https://www.scrapethissite.com/pages/forms/?q=\"\n",
    "soup = get_my_soup(main_link)\n",
    "\n",
    "#getting the links to all the pages\n",
    "temp = find_all_class(soup, 'ul', 'pagination')\n",
    "\n",
    "for a in find_all_class(temp[0], 'a', ''):\n",
    "    page_hrefs.append('https://www.scrapethissite.com' + a['href'])\n",
    "\n",
    "#going forward with only three links\n",
    "page_hrefs = page_hrefs[:3]\n",
    "\n",
    "# #looping through the first three pages\n",
    "for link in page_hrefs:\n",
    "\n",
    "    soup = get_my_soup(link)\n",
    "\n",
    "    #looping to get all the details from each page\n",
    "    for a in find_all_class(soup, 'tr', 'team'):\n",
    "\n",
    "        name = find_first(a, 'td', 'name')\n",
    "        yr = find_first(a, 'td', 'year')\n",
    "        w = find_first(a, 'td', 'wins')\n",
    "        l = find_first(a, 'td', 'losses')\n",
    "        ot = find_first(a, 'td', 'ot-losses')\n",
    "        pct = find_first(a, 'td', 'pct')\n",
    "        g_f = find_first(a, 'td', 'gf')\n",
    "        g_a = find_first(a, 'td', 'ga')\n",
    "        diff = find_first(a, 'td', 'diff')\n",
    "        \n",
    "        team_names.append(name.text.strip())\n",
    "        year.append(yr.text.strip())\n",
    "        wins.append(w.text.strip())\n",
    "        losses.append(l.text.strip())\n",
    "        OT_losses.append(ot.text.strip())\n",
    "        win_percent.append(pct.text.strip())\n",
    "        gf.append(g_f.text.strip())\n",
    "        ga.append(g_a.text.strip())\n",
    "        differences.append(diff.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e45e12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset with the extracted data\n",
    "df = pd.DataFrame({'Team names': team_names, 'Year' : year, 'Wins': wins,'Losses': losses, 'OT Losses' : OT_losses, 'Win((%))': win_percent, 'GF' : gf, 'GA' : ga, '+/-': differences})\n",
    "df.to_csv('dataset2.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b231660",
   "metadata": {},
   "source": [
    "End of Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
